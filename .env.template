# ============================================================================
# BrowserOS KB Research - Environment Configuration Template
# ============================================================================
# Copy this file to .env and fill in your values
# Never commit .env to version control!
# ============================================================================

# ============================================================================
# AGENT MODE
# ============================================================================
# Options: sdk, mcp, http, local, docker, hybrid
# hybrid = try multiple connection types automatically
AGENT_MODE=hybrid

# ============================================================================
# API KEYS (Required for cloud services)
# ============================================================================

# Ollama Cloud Service API Key
# Get from: https://ollama.ai/keys
OLLAMA_API_KEY=your-ollama-api-key-here

# OpenRouter API Key
# Get from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your-openrouter-api-key-here

# GitHub Token (for accessing repos, issues, PRs)
# Get from: https://github.com/settings/tokens
GITHUB_TOKEN=your-github-token-here

# ============================================================================
# CONNECTION MODES (Optional - defaults from config.yml)
# ============================================================================

# Ollama connection mode
# Options: http, sdk, mcp, docker, local
OLLAMA_MODE=http

# OpenRouter connection mode
# Options: http, sdk, mcp
OPENROUTER_MODE=http

# ============================================================================
# CUSTOM ENDPOINTS (Optional)
# ============================================================================

# Ollama custom endpoint (if not using default)
# OLLAMA_BASE_URL=https://your-ollama-instance.com/v1

# OpenRouter custom endpoint (if proxying)
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# MCP Server URL (if using MCP)
# MCP_SERVER_URL=mcp://localhost:3000

# ============================================================================
# MODEL SELECTION (Optional)
# ============================================================================

# Ollama model
# OLLAMA_MODEL=llama2

# OpenRouter model
# OPENROUTER_MODEL=anthropic/claude-3-sonnet

# ============================================================================
# RESEARCH CONFIGURATION
# ============================================================================

# Force full KB regeneration (normally false)
FORCE_UPDATE=false

# Enable/disable specific sources
# FETCH_GITHUB_REPOS=true
# FETCH_GITHUB_ISSUES=true
# FETCH_WEB_SOURCES=true

# ============================================================================
# LOGGING
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================================
# DOCKER CONFIGURATION (if using Docker)
# ============================================================================

# Container name prefix
# COMPOSE_PROJECT_NAME=browseros-kb

# Ollama container settings
# OLLAMA_CONTAINER_NAME=ollama-service
# OLLAMA_PORT=11434

# ============================================================================
# PERFORMANCE TUNING
# ============================================================================

# Maximum concurrent requests
# MAX_WORKERS=5

# Request timeout (seconds)
# REQUEST_TIMEOUT=60

# Cache duration (days)
# CACHE_DURATION=7

# ============================================================================
# SECURITY (Optional - for production)
# ============================================================================

# Encryption key for secrets (if using encrypted storage)
# ENCRYPTION_KEY=your-encryption-key-here

# ============================================================================
# MONITORING (Optional - for advanced users)
# ============================================================================

# Enable Prometheus metrics
# ENABLE_METRICS=false
# METRICS_PORT=9090

# Enable OpenTelemetry tracing
# ENABLE_TRACING=false
# OTLP_ENDPOINT=http://localhost:4318

# ============================================================================
# NOTES
# ============================================================================
# 1. This file should be in .gitignore - never commit secrets!
# 2. Values in this file override config.yml settings
# 3. Required: OLLAMA_API_KEY, OPENROUTER_API_KEY (for cloud mode)
# 4. Optional: Everything else has defaults in config.yml
# 5. For local/docker mode, API keys are optional
